{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = dataloader.imagenet_loader(bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg19(pretrained=True)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(epoch):\n",
    "    top1_accuracy = 0.\n",
    "    top5_accuracy = 0.\n",
    "    loss = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for idx, (inputs, targets) in tqdm_notebook(enumerate(valid_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss += criterion(outputs, targets).detach().cpu().item()\n",
    "\n",
    "        topk = outputs.topk(5,dim=1)[1]\n",
    "        top1_accuracy += topk[:,0].eq(targets).sum().cpu().item()\n",
    "        top5_accuracy += topk.eq(torch.stack([targets]*5,dim=1)).max(1)[0].sum().cpu().item()\n",
    "    \n",
    "    top1_accuracy /= len(valid_loader.dataset)\n",
    "    top5_accuracy /= len(valid_loader.dataset)\n",
    "    loss /= len(valid_loader.dataset)\n",
    "\n",
    "    print('Classification')\n",
    "    print(f'===> Test Loss: {loss:.4f}, Top1-Acc: {top1_accuracy*100:.4f}, Top5-Acc: {top5_accuracy*100:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(0) # ===> Test Loss: 0.0373, Top1-Acc: 70.6800, Top5-Acc: 89.9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(directory, bboxes_cam, bboxes_ours):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    with open(join(directory,'cam.json'), 'a') as json_file:\n",
    "        json.dump(bboxes_cam, json_file)\n",
    "\n",
    "    with open(join(directory,'ours_0.2_10.json'), 'a') as json_file:\n",
    "        json.dump(bboxes_ours, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os.path import join\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from cam import CAM\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = CAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = map.valid_dataset.data_dict\n",
    "input_files = map.valid_dataset.img_files\n",
    "img_dir = map.valid_dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/50000 [00:04<17:10:38,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization Accuracy\n",
      "===> CAM: 0.2, Propose: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bboxes_cam = {}\n",
    "bboxes_ours = {}\n",
    "\n",
    "count = 0\n",
    "correct_cam = 0\n",
    "correct_propose = 0\n",
    "for data_idx in tqdm(range(len(data_dict))):\n",
    "    count += 1\n",
    "    \n",
    "    # get true bbox\n",
    "    input_file = input_files[data_idx]\n",
    "    img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "    bboxes_true = data_dict[input_file][1]\n",
    "    bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "    \n",
    "    # get input and target\n",
    "    input, target = map.get_item(data_idx)\n",
    "    target = target.cpu().item()\n",
    "    \n",
    "    ''' CAM origin version '''\n",
    "    _, _, _, _, bbox_pred = map.get_values(data_idx, target, th1=0.2, phase='test')\n",
    "    \n",
    "    ''' CAM propose version '''\n",
    "    _, _, _, _, _, bbox_propose = map.get_values(data_idx, target, th1=0.2, th2=10, mc=50, phase='train')\n",
    "    \n",
    "    ''' get iou '''\n",
    "    iou_preds, iou_propose = [], []\n",
    "    for bbox_true in bboxes_true:\n",
    "        iou_preds.append(util.get_iou(bbox_true, bbox_pred))\n",
    "        iou_propose.append(util.get_iou(bbox_true, bbox_propose))\n",
    "        \n",
    "        \n",
    "        correct_cam += max(np.array(iou_preds) >= 0.5).astype(np.int)\n",
    "        correct_propose += max(np.array(iou_propose) >= 0.5).astype(np.int)\n",
    "    \n",
    "    ''' save bboxes for every 100 iteration '''\n",
    "    bboxes_cam[input_file] = bbox_pred\n",
    "    bboxes_ours[input_file] = bbox_propose\n",
    "    \n",
    "    if data_idx+1 % 100 == 0:\n",
    "        save_json('bbox',bboxes_cam, bboxes_ours)\n",
    "        bboxes_cam, bboxes_ours = {}, {}\n",
    "    \n",
    "    if data_idx == 4:\n",
    "        break\n",
    "        \n",
    "print('Localization Accuracy')\n",
    "print(f'===> CAM: {correct_cam/count}, Propose: {correct_propose/count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification & Localization (top-1 Loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = dataloader.imagenet_loader(bs=32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = vgg19(pretrained=True)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = join('/','data2','imagenet')\n",
    "img_dir = join(base_dir, 'valid_img')\n",
    "lbl_dir = join(base_dir, 'valid_lbl')\n",
    "input_files = os.listdir(img_dir)\n",
    "lbl_files = os.listdir(lbl_dir)\n",
    "input_files.sort(key=util.natural_keys)\n",
    "lbl_files.sort(key=util.natural_keys)\n",
    "_, class_dict_name2idx = dataloader.get_class_dict(base_dir)\n",
    "data_dict = dataloader.get_data_dict(lbl_dir,lbl_files,class_dict_name2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join('bbox','ours_0.4_0.4.json'), 'r') as json_file:\n",
    "    for line in json_file:\n",
    "        pass \n",
    "\n",
    "splits = [aa for aa in re.split('{|}|\"|: |\\[|\\, |\\]|\\n',line) if aa is not '']\n",
    "\n",
    "bboxes_dict = {splits[i]: (int(splits[i+1]), int(splits[i+2]), int(splits[i+3]), int(splits[i+4]))\n",
    "               for i in np.arange(0,len(splits),5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bboxes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37543c7edb114c31b03f880294ffe61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification & Localization\n",
      "===> Top1-Loc: 0.39859375, Top5-Loc: 0.50203125\n"
     ]
    }
   ],
   "source": [
    "# def test_accuracy(epoch):\n",
    "top1_acc_loc = 0.\n",
    "top5_acc_loc = 0.\n",
    "loss = 0.\n",
    "\n",
    "model.eval()\n",
    "for idx, (inputs, targets) in tqdm_notebook(enumerate(valid_loader)):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss += criterion(outputs, targets).detach().cpu().item()\n",
    "\n",
    "    topk = outputs.topk(5,dim=1)[1]\n",
    "    top1_acc_clss = topk[:,0].eq(targets).cpu().numpy()\n",
    "    top5_acc_clss = topk.eq(torch.stack([targets]*5,dim=1)).max(1)[0].cpu().numpy()\n",
    "    \n",
    "    gtknown_acc_locs = []\n",
    "    for data_idx in range(idx,idx+32):\n",
    "        # get true bbox\n",
    "        input_file = input_files[data_idx]\n",
    "        img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "        bboxes_true = data_dict[input_file][1]\n",
    "        bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "\n",
    "        # get ours bbox\n",
    "        bbox_propose = bboxes_dict[input_file]\n",
    "\n",
    "        # get iou\n",
    "        iou_propose = []\n",
    "        for bbox_true in bboxes_true:\n",
    "            iou_propose.append(util.get_iou(bbox_true, bbox_propose))\n",
    "        iou_propose = max(np.array(iou_propose) >= 0.5).astype(np.int)\n",
    "        gtknown_acc_locs.append(iou_propose)\n",
    "        \n",
    "    top1_acc_locs = np.logical_and(top1_acc_clss, gtknown_acc_locs)\n",
    "    top5_acc_locs = np.logical_and(top5_acc_clss, gtknown_acc_locs)\n",
    "    \n",
    "    top1_acc_loc += top1_acc_locs.sum()\n",
    "    top5_acc_loc += top5_acc_locs.sum()\n",
    "    \n",
    "    if idx == 200:\n",
    "        break\n",
    "\n",
    "top1_acc_loc /= (32*200)\n",
    "top5_acc_loc /= (32*200)\n",
    "print('Classification & Localization')\n",
    "print(f'===> Top1-Loc: {top1_acc_loc}, Top5-Loc: {top5_acc_loc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from cam import CAM\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = CAM()\n",
    "\n",
    "class_dict = dataloader.get_class_dict('/data2/imagenet')[0]\n",
    "data_dict = map.valid_dataset.data_dict\n",
    "input_files = map.valid_dataset.img_files\n",
    "img_dir = map.valid_dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_plt(data_idx, th1=0.2, th2=10, mc=15):\n",
    "    # get true bbox\n",
    "    input_file = input_files[data_idx]\n",
    "    img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "    bboxes_true = data_dict[input_file][1]\n",
    "    bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "    \n",
    "    # get input, target, and topk\n",
    "    input, target = map.get_item(data_idx)\n",
    "    target = target.cpu().item()\n",
    "\n",
    "    topk_idxs = map.topk(input)\n",
    "    top1_correct = target in topk_idxs[:1]\n",
    "    top5_correct = target in topk_idxs[:5]\n",
    "    \n",
    "    att_idx = target\n",
    "    \n",
    "    # origin\n",
    "    img, heatmap_origin, boolmap, boolmap_biggest, \\\n",
    "    bbox_pred = map.get_values(data_idx,att_idx, th1=0.2, phase='test')\n",
    "    \n",
    "    # propose\n",
    "    _, heatmap_mean, heatmap_std, boolmap_propose, boolmap_biggest_propose, \\\n",
    "    bbox_propose = map.get_values(data_idx, att_idx, th1, th2, mc, phase='train')\n",
    "    heatmap_std_max = heatmap_std.max()\n",
    "    \n",
    "    # save the plot\n",
    "    fig, ax = plt.subplots(2,6,figsize=(21,7))\n",
    "\n",
    "    ax[0,0].imshow(img)\n",
    "    ax[0,0].set_title('origin')\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    ax[0,1].imshow(heatmap_origin)\n",
    "    ax[0,1].set_title('heatmap')\n",
    "    ax[0,1].axis('off')\n",
    "\n",
    "    ax[0,2].imshow(img)\n",
    "    ax[0,2].imshow(heatmap_origin, alpha=0.5, cmap='jet')\n",
    "    ax[0,2].set_title(f'CAM \"{class_dict[target]}\"\\n Top-1: {top1_correct}, Top-5: {top5_correct}')\n",
    "    ax[0,2].axis('off')\n",
    "\n",
    "    ax[0,3].imshow(Image.fromarray((boolmap*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[0,3].set_title('boolean map')\n",
    "    ax[0,3].axis('off')\n",
    "\n",
    "    ax[0,4].imshow(Image.fromarray((boolmap_biggest*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[0,4].set_title('biggest boolean map')\n",
    "    ax[0,4].axis('off')\n",
    "\n",
    "    ax[0,5].imshow(img)\n",
    "    for bbox_true in bboxes_true:\n",
    "        rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                      linewidth=2,edgecolor='g',facecolor='none')\n",
    "        ax[0,5].add_patch(rect_true)\n",
    "    rect_pred = patches.Rectangle((bbox_pred[0],bbox_pred[1]),bbox_pred[2],bbox_pred[3],\n",
    "                                  linewidth=2,edgecolor='r',facecolor='none')\n",
    "    ax[0,5].add_patch(rect_pred)\n",
    "    ax[0,5].set_title('bounding box')\n",
    "    ax[0,5].axis('off')\n",
    "\n",
    "\n",
    "    ax[1,0].imshow(heatmap_mean, cmap='gray')\n",
    "    ax[1,0].set_title('heatmap_mean')\n",
    "    ax[1,0].axis('off')\n",
    "\n",
    "    ax[1,1].imshow(heatmap_std, cmap='gray')\n",
    "    ax[1,1].set_title(f'heatmap_std\\n max value: {heatmap_std_max:.01f}')\n",
    "    ax[1,1].axis('off')\n",
    "\n",
    "    im1 = ax[1,2].imshow(heatmap_mean, cmap='Reds', label='mean')\n",
    "    im2 = ax[1,2].imshow(heatmap_std, cmap='Blues', label='std', alpha=0.5)\n",
    "    ax[1,2].set_title('overlap')\n",
    "    ax[1,2].axis('off')\n",
    "    patch = [patches.Patch(color=im1.cmap(150), label='mean'), \n",
    "             patches.Patch(color=im2.cmap(150), label='std')]\n",
    "    ax[1,2].legend(handles=patch, loc='best')\n",
    "\n",
    "    ax[1,3].imshow(Image.fromarray((boolmap_propose*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[1,3].set_title('boolean map')\n",
    "    ax[1,3].axis('off')\n",
    "\n",
    "    ax[1,4].imshow(Image.fromarray((boolmap_biggest_propose*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[1,4].set_title('biggest boolean map')\n",
    "    ax[1,4].axis('off')\n",
    "\n",
    "    ax[1,5].imshow(img)\n",
    "    for bbox_true in bboxes_true:\n",
    "        rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                      linewidth=2,edgecolor='g',facecolor='none')\n",
    "        ax[1,5].add_patch(rect_true)\n",
    "    rect_pred = patches.Rectangle((bbox_propose[0],bbox_propose[1]),bbox_propose[2],bbox_propose[3],\n",
    "                                  linewidth=2,edgecolor='r',facecolor='none')\n",
    "    ax[1,5].add_patch(rect_pred)\n",
    "    ax[1,5].set_title('bounding box')\n",
    "    ax[1,5].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "#     plt.savefig(join('save',f'{data_idx:05d}.png'))\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for data_idx in tqdm_notebook(range(1000)):\n",
    "#     save_result_plt(data_idx, th1=0.4, th2=0.4, mc=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result_plt(129,th1=0.4, th2=0.4, mc=50) # good hyperparam... maybe! th1=0.4, th2=0.4, mc=50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
